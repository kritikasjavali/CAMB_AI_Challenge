{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import os\n",
    "from yt_dlp import YoutubeDL\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import stopwordsiso as stopwords\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "# Initialize YouTube API\n",
    "youtube = build('youtube', 'v3', developerKey='AIzaSyBOvVwCkJKIY3RCWAUogb9Y8UbGjMN6fec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_videos(query, max_results=100):\n",
    "    \"\"\"Search for videos by query and return a list of video IDs.\"\"\"\n",
    "    try:\n",
    "        search_response = youtube.search().list(\n",
    "            q=query,\n",
    "            part='id',\n",
    "            type='video',\n",
    "            maxResults=max_results\n",
    "        ).execute()\n",
    "        \n",
    "        video_ids = [item['id']['videoId'] for item in search_response['items']]\n",
    "        return video_ids\n",
    "    except HttpError as e:\n",
    "        print(f\"An HTTP error {e.resp.status} occurred:\\n{e.content}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "query = \"Gaeilge i mo chro√≠\"  # Adjust your search query as needed\n",
    "video_ids = search_videos(query)\n",
    "print(video_ids)\n",
    "print(f\"Found {len(video_ids)} videos with Irish subtitles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate URLs\n",
    "video_url = [f\"https://www.youtube.com/watch?v={id}\" for id in video_ids]\n",
    "\n",
    "# Print URLs\n",
    "for url in video_url:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_urls='/Users/kritikajavali/Documents/CAMB/video_urls.txt'\n",
    "video_id='/Users/kritikajavali/Documents/CAMB/video_id.txt'\n",
    "with open (video_urls,'w') as file:\n",
    "    for url in video_url:\n",
    "        file.writelines(f\"{url}\\n\")\n",
    "\n",
    "with open (video_id,'w') as file:\n",
    "    for video in video_ids:\n",
    "        file.writelines(f\"{video}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_download_options = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'outtmpl': '/Users/kritikajavali/Documents/CAMB/audios/%(id)s.%(ext)s',  # Saves audio files to ./audios directory with video ID as filename\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'wav',  # or mp3\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "    'quiet': False\n",
    "}\n",
    "\n",
    "with YoutubeDL(audio_download_options) as ydl:\n",
    "    ydl.download(video_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in video_ids:\n",
    "    # Path where you want to save the JSON file\n",
    "    output_file_path = f\"transcripts/{video}.json\"\n",
    "\n",
    "    try:\n",
    "        # Retrieve the available transcripts\n",
    "        transcript_list = YouTubeTranscriptApi.list_transcripts(video)\n",
    "\n",
    "        # Choose the transcript you want (e.g., translating it to 'ga' - Irish)\n",
    "        transcript = transcript_list.find_transcript(['en']).translate('ga').fetch()\n",
    "\n",
    "        # Serialize the transcript data to JSON\n",
    "        transcript_json = json.dumps(transcript, ensure_ascii=False, indent=4)\n",
    "\n",
    "        # Write the JSON data to a file\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(transcript_json)\n",
    "\n",
    "        print(f\"Transcript saved to {output_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directories containing the audio files and transcripts\n",
    "audio_files_dir = '/Users/kritikajavali/Documents/CAMB/audios'\n",
    "transcripts_dir = '/Users/kritikajavali/Documents/CAMB/transcripts'\n",
    "\n",
    "# Path to the directory where you want to organize the folders by video ID\n",
    "ORGANIZED_DIR = '/Users/kritikajavali/Documents/CAMB/audios_transcripts'\n",
    "\n",
    "# Ensure the organized directory exists\n",
    "os.makedirs(ORGANIZED_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "for video_id in video_ids:\n",
    "    # Create a directory for each video ID\n",
    "    video_id_dir = os.path.join(ORGANIZED_DIR, video_id)\n",
    "    os.makedirs(video_id_dir, exist_ok=True)\n",
    "\n",
    "    # Move the audio file for this video ID\n",
    "    audio_file_path = os.path.join(audio_files_dir, f\"{video_id}.wav\")  # Update the extension if necessary\n",
    "    if os.path.exists(audio_file_path):\n",
    "        shutil.move(audio_file_path, os.path.join(video_id_dir, os.path.basename(audio_file_path)))\n",
    "\n",
    "    # Move the transcript for this video ID\n",
    "    transcript_file_path = os.path.join(transcripts_dir, f\"{video_id}.json\")  # Update the extension if necessary\n",
    "    if os.path.exists(transcript_file_path):\n",
    "        shutil.move(transcript_file_path, os.path.join(video_id_dir, os.path.basename(transcript_file_path)))\n",
    "\n",
    "print(\"Files have been organized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each directory in the source directory\n",
    "for video_id in os.listdir(ORGANIZED_DIR):\n",
    "    dir_path = os.path.join(ORGANIZED_DIR, video_id)\n",
    "    if os.path.isdir(dir_path):  # Make sure it's a directory\n",
    "        for file in os.listdir(dir_path):\n",
    "            if file.endswith(\".wav\"):  # Check for audio files\n",
    "                audio_file_path = os.path.join(dir_path, file)\n",
    "                base_name = os.path.splitext(file)[0]\n",
    "\n",
    "                # Assuming the transcript file has the same base name but with a .json extension\n",
    "                transcript_file_path = os.path.join(dir_path, f\"{base_name}.json\")\n",
    "\n",
    "                # Proceed only if both audio and transcript files exist\n",
    "                if os.path.exists(transcript_file_path):\n",
    "                    # Load the audio file\n",
    "                    audio = AudioSegment.from_file(audio_file_path)\n",
    "\n",
    "                    # Load the transcript data from the JSON file\n",
    "                    with open(transcript_file_path, 'r', encoding='utf-8') as f:\n",
    "                        transcript_data = json.load(f)\n",
    "\n",
    "                    # Process each transcript entry\n",
    "                    for i, entry in enumerate(transcript_data):\n",
    "                        # Calculate the start and end times in milliseconds\n",
    "                        start_time = int(entry['start'] * 1000)\n",
    "                        end_time = int((entry['start'] + entry['duration']) * 1000)\n",
    "                        \n",
    "                        # Extract the audio segment\n",
    "                        segment = audio[start_time:end_time]\n",
    "                        \n",
    "                        # Define the base filename for the audio and transcript files\n",
    "                        segment_filename = f\"{base_name}_{i:03d}\"\n",
    "                        \n",
    "                        # Save the audio segment\n",
    "                        segment_path = os.path.join(dir_path, f\"{segment_filename}.wav\")\n",
    "                        segment.export(segment_path, format=\"wav\")\n",
    "                        \n",
    "                        # Save the corresponding transcript text\n",
    "                        transcript_path = os.path.join(dir_path, f\"{segment_filename}.txt\")\n",
    "                        with open(transcript_path, 'w', encoding='utf-8') as f:\n",
    "                            f.write(entry['text'])\n",
    "\n",
    "print(\"Audio segments and transcripts have been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each directory in the source directory\n",
    "for dir_path in ORGANIZED_DIR.iterdir():\n",
    "    if dir_path.is_dir():\n",
    "        # Process each .txt file in the directory\n",
    "        for txt_file_path in dir_path.glob(\"*.txt\"):\n",
    "            with open(txt_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "\n",
    "            # Check if text contains \"[Ceol]\"\n",
    "            if \"[Ceol]\" in text:\n",
    "                # Prepare the path for the corresponding .wav file\n",
    "                wav_file_path = dir_path / f\"{txt_file_path.stem}.wav\"\n",
    "                \n",
    "                # Delete the text file\n",
    "                txt_file_path.unlink()\n",
    "\n",
    "                # Delete the .wav file if it exists\n",
    "                if wav_file_path.exists():\n",
    "                    wav_file_path.unlink()\n",
    "                \n",
    "                print(f\"Deleted {txt_file_path.name} and {wav_file_path.name} due to the presence of '[Ceol]'.\")\n",
    "                continue  # Important to skip the rest of the loop if the file is deleted\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Irish Spacy model\n",
    "nlp = spacy.blank(\"ga\")\n",
    "\n",
    "# Fetch Irish stop words using stopwordsiso\n",
    "irish_stopwords = stopwords.stopwords(\"ga\")\n",
    "\n",
    "# Function to normalize text\n",
    "def normalize_text(text, nlp, stopwords):\n",
    "    doc = nlp(text)\n",
    "    # Filter out stop words and punctuation\n",
    "    filtered_tokens = [token.text for token in doc if token.text not in stopwords and not token.is_punct]\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "# Process each directory and file in the source directory\n",
    "for dir_path in ORGANIZED_DIR.iterdir():\n",
    "    if dir_path.is_dir():  # Make sure it's a directory\n",
    "        for txt_file_path in dir_path.glob(\"*.txt\"):\n",
    "            with open(txt_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "\n",
    "            # Normalize the text\n",
    "            normalized_text = normalize_text(text, nlp, irish_stopwords)\n",
    "            \n",
    "            # Construct the normalized file path\n",
    "            normalized_file_path = txt_file_path.parent / f\"{txt_file_path.stem}_normalized.txt\"\n",
    "            with open(normalized_file_path, \"w\", encoding=\"utf-8\") as nf:\n",
    "                nf.write(normalized_text)\n",
    "            \n",
    "            print(f\"Processed and saved normalized text for {txt_file_path.name}.\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('camb': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a89fadbea37b12d2b8035fa2a6bfeace965ce9455eaf87ef1b801d00ad2ac75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
